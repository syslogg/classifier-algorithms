{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syslogg/classifier-algorithms/blob/master/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BF8hX1CTgj6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementação Redes Neurais Multicamada (MLP)\n",
        "- Hendy Rodrigues F. Silva (1510081)"
      ]
    },
    {
      "metadata": {
        "id": "OD6VJgH0KxSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "8cada8b8-3195-4631-baeb-c1c13a41e127"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math as m\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "import warnings\n",
        "import random as rnd\n",
        "from random import randint\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "ds_derm = pd.read_csv('derm.csv')\n",
        "ds_derm.drop(['age'], axis=1,inplace=True) # Descarta a IDADE\n",
        "ds_derm.head()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>erythema</th>\n",
              "      <th>scaling</th>\n",
              "      <th>definite_borders</th>\n",
              "      <th>itching</th>\n",
              "      <th>koebner_phenomenon</th>\n",
              "      <th>polygonal_papules</th>\n",
              "      <th>follicular_papules</th>\n",
              "      <th>oral_mucosal_involvement</th>\n",
              "      <th>knee_and_elbow_involvement</th>\n",
              "      <th>scalp_involvement</th>\n",
              "      <th>...</th>\n",
              "      <th>focal_hypergranulosis</th>\n",
              "      <th>disappearance_of_the_granular_layer</th>\n",
              "      <th>vacuolisation_and_damage_of_basal_layer</th>\n",
              "      <th>spongiosis</th>\n",
              "      <th>saw-tooth_appearance_of_retes</th>\n",
              "      <th>follicular_horn_plug</th>\n",
              "      <th>perifollicular_parakeratosis</th>\n",
              "      <th>inflammatory_monoluclear_inflitrate</th>\n",
              "      <th>band-like_infiltrate</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   erythema  scaling  definite_borders  itching  koebner_phenomenon  \\\n",
              "0         2        2                 0        3                   0   \n",
              "1         3        3                 3        2                   1   \n",
              "2         2        1                 2        3                   1   \n",
              "3         2        2                 2        0                   0   \n",
              "4         2        3                 2        2                   2   \n",
              "\n",
              "   polygonal_papules  follicular_papules  oral_mucosal_involvement  \\\n",
              "0                  0                   0                         0   \n",
              "1                  0                   0                         0   \n",
              "2                  3                   0                         3   \n",
              "3                  0                   0                         0   \n",
              "4                  2                   0                         2   \n",
              "\n",
              "   knee_and_elbow_involvement  scalp_involvement  ...    \\\n",
              "0                           1                  0  ...     \n",
              "1                           1                  1  ...     \n",
              "2                           0                  0  ...     \n",
              "3                           3                  2  ...     \n",
              "4                           0                  0  ...     \n",
              "\n",
              "   focal_hypergranulosis  disappearance_of_the_granular_layer  \\\n",
              "0                      0                                    0   \n",
              "1                      0                                    0   \n",
              "2                      2                                    0   \n",
              "3                      0                                    3   \n",
              "4                      2                                    2   \n",
              "\n",
              "   vacuolisation_and_damage_of_basal_layer  spongiosis  \\\n",
              "0                                        0           3   \n",
              "1                                        0           0   \n",
              "2                                        2           3   \n",
              "3                                        0           0   \n",
              "4                                        3           2   \n",
              "\n",
              "   saw-tooth_appearance_of_retes  follicular_horn_plug  \\\n",
              "0                              0                     0   \n",
              "1                              0                     0   \n",
              "2                              2                     0   \n",
              "3                              0                     0   \n",
              "4                              3                     0   \n",
              "\n",
              "   perifollicular_parakeratosis  inflammatory_monoluclear_inflitrate  \\\n",
              "0                             0                                    1   \n",
              "1                             0                                    1   \n",
              "2                             0                                    2   \n",
              "3                             0                                    3   \n",
              "4                             0                                    2   \n",
              "\n",
              "   band-like_infiltrate  class  \n",
              "0                     0      2  \n",
              "1                     0      1  \n",
              "2                     3      3  \n",
              "3                     0      1  \n",
              "4                     3      3  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "metadata": {
        "id": "wtXCovkIXNAR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "last_col = ds_derm.columns[len(ds_derm.columns)-1]\n",
        "classes = list(ds_derm[last_col].unique())\n",
        "len_cols = len(ds_derm.columns) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dhq90SOeWcJJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# One Hot Codification\n",
        "# Codificacao usando arrays de zeros e um para cada classe\n",
        "def one_hot_encoding(classes):\n",
        "    cl_onehot = np.zeros((len(classes),len(classes)),dtype=int)\n",
        "    np.fill_diagonal(cl_onehot,1)\n",
        "    r = [(classes[i], cl) for i, cl in enumerate(cl_onehot)]\n",
        "    return r\n",
        "\n",
        "# Codifica as classes esperadas\n",
        "def encode_expected(expected, encoded_class):\n",
        "    return np.array([ list(filter(lambda e: e[0] == x, encoded_class))[0][1] for x in expected ])\n",
        "\n",
        "# Codifica todas as classes do dataset\n",
        "def encode_class(ds):\n",
        "    return one_hot_encoding(pd.unique(ds.iloc[:,-1:].values.flatten()))\n",
        "\n",
        "# Decodifica o resultado\n",
        "def decode_result(encoded_class, value):\n",
        "    if sum(value) != 1:\n",
        "        value = list(encoded_class[randint(0,len(encoded_class)-1)][1])\n",
        "    return list(filter(lambda x: list(x[1]) == value,encoded_class))[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGnfZwCYK5Sm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Classe para representar a camada oculta\n",
        "class NeuronLayer():\n",
        "    def __init__(self, number_of_neurons, number_of_inputs_per_neuron):\n",
        "        self.synaptic_weights = 2 * np.random.random((number_of_inputs_per_neuron, number_of_neurons)) - 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5Xz6SfJLEAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Classe para representar a rede neural (por padrao foi feita com 2 camadas)\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    # Metodo constructor\n",
        "    def __init__(self, layer1, layer2):\n",
        "        self.layer1 = layer1\n",
        "        self.layer2 = layer2\n",
        "        \n",
        "    # Função Sigmoide\n",
        "    def __sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Derivada da Sigmoide\n",
        "    def __sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "    \n",
        "    # Treinar Rede - Utilização: Regra Delta\n",
        "    def train(self, inputs_training, outputs_training, num_interation):\n",
        "        for interate in range(0,num_interation):\n",
        "            \n",
        "            # Calcula o resultado do neuronio\n",
        "            output_layer1, output_layer2 = self.__think(inputs_training)\n",
        "            \n",
        "            # Calcula o erro da layer 2\n",
        "            layer2_error = outputs_training - output_layer2\n",
        "            layer2_delta = layer2_error * self.__sigmoid_derivative(output_layer2)\n",
        "            \n",
        "            # Calcula o erro da layer 1\n",
        "            layer1_error = layer2_delta.dot(self.layer2.synaptic_weights.T)\n",
        "            layer1_delta = layer1_error * self.__sigmoid_derivative(output_layer1)\n",
        "            \n",
        "            # Quanto de ajuste vai ter no W das camadas \n",
        "            layer1_adjustment = inputs_training.T.dot(layer1_delta)\n",
        "            layer2_adjustment = output_layer1.T.dot(layer2_delta)\n",
        "            \n",
        "            #Ajusta os pesos dos neuronios\n",
        "            self.layer1.synaptic_weights += layer1_adjustment\n",
        "            self.layer2.synaptic_weights += layer2_adjustment\n",
        "            \n",
        "            \n",
        "            \n",
        "    def __think(self, input_training):\n",
        "        output_layer1 = self.__sigmoid(np.dot(input_training, self.layer1.synaptic_weights))\n",
        "        output_layer2 = self.__sigmoid(np.dot(output_layer1, self.layer2.synaptic_weights))\n",
        "        return output_layer1, output_layer2\n",
        "    \n",
        "    \n",
        "    def predict(self, input_):\n",
        "        h, out = self.__think(input_)\n",
        "        result = [1 if o >= 0.5 else 0 for o in out]\n",
        "        return result\n",
        "        \n",
        "    \n",
        "    def print_weights(self):\n",
        "        \n",
        "        print('Camada 1:')\n",
        "        print(self.layer1.synaptic_weights)\n",
        "        print('Camada 2:')\n",
        "        print(self.layer2.synaptic_weights)\n",
        "    \n",
        "    \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-MSQtJRWGJF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(dataset_train, dataset_test):\n",
        "    count_correct = 0\n",
        "    count_incorrect = 0\n",
        "    \n",
        "    count_by_classes_correct = [0 for i in range(0,len(classes))]\n",
        "    count_by_classes_incorrect = [0 for i in range(0,len(classes))]\n",
        "    \n",
        "    # Codifica as classes do dataset\n",
        "    encoded_class = encode_class(dataset_train)\n",
        "    \n",
        "    # Rede neural com 2 Camadas, Uma com 16 Neuronios e Outra com 6 Neuronios.\n",
        "    \n",
        "    # Camada 1: Cria 16 Neuronios com 33 entradas (quantidade de inputs do dataset dermatology)\n",
        "    l1 = NeuronLayer(16,len_cols)\n",
        "    # Camada 2: Cria 12 Neuronios com 6 entradas vinda do outro neuronio (Camada de output)\n",
        "    l2 = NeuronLayer(len(classes), 16)\n",
        "    \n",
        "    neural_network = NeuralNetwork(l1, l2)\n",
        "    \n",
        "    inputs = dataset_train.iloc[:,:-1].values\n",
        "    outputs = dataset_train.iloc[:,-1:].values\n",
        "    \n",
        "    outputs_encoded = encode_expected(outputs,encoded_class)\n",
        "    \n",
        "    neural_network.train(inputs, outputs_encoded, 10000)\n",
        "    \n",
        "    for index, row in dataset_test.iterrows():\n",
        "        \n",
        "        tuple_t = list(row)\n",
        "        tuple_t.pop()\n",
        "        \n",
        "        r = neural_network.predict(tuple_t) # Efetua o resultado pelo valor da rede\n",
        "        \n",
        "        result = decode_result(encoded_class, r)\n",
        "        \n",
        "        #Result\n",
        "        if result == row[last_col]:\n",
        "            count_correct += 1\n",
        "            count_by_classes_correct[classes.index(result)] += 1\n",
        "        else:\n",
        "            count_incorrect += 1\n",
        "            count_by_classes_incorrect[classes.index(result)] += 1\n",
        "        \n",
        "    return count_correct, count_incorrect, count_by_classes_correct, count_by_classes_incorrect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nTx6PS_oWGZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def seperate_ds_by_class(dataset, percentage):\n",
        "    rds_train = pd.DataFrame()\n",
        "    rds_test = pd.DataFrame()\n",
        "    \n",
        "    for c in classes:\n",
        "        nds = dataset[dataset[last_col]==c]\n",
        "        \n",
        "        # Essa função pega o dataset e separa uma fração dele, e reordena\n",
        "        ds_train = nds.sample(frac=percentage, random_state=randint(0,15100))\n",
        "        # Pega o que sobrou do dataset de treino\n",
        "        ds_test = nds.drop(ds_train.index) \n",
        "        \n",
        "        rds_train = rds_train.append(ds_train)\n",
        "        rds_test = rds_test.append(ds_test)\n",
        "        \n",
        "    rds_train = rds_train.reset_index() # Reiniciar indice\n",
        "    rds_test = rds_test.reset_index() # Reiniciar indice\n",
        "\n",
        "    rds_train.drop('index',1,inplace=True) # Retirar coluna index\n",
        "    rds_test.drop('index',1,inplace=True) # Retirar coluna index\n",
        "    \n",
        "    return (rds_train, rds_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hs08EUenWGdf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_nth(ds,percentage, number):\n",
        "    percentages_correct = list()\n",
        "    prob_correct_by_class = []\n",
        "    \n",
        "    for i in range(0,number):\n",
        "        ds_train, ds_test = seperate_ds_by_class(ds,percentage)\n",
        "        correct, incorrect, count_by_classes_correct, count_by_classes_incorrect = train(ds_train, ds_test)\n",
        "\n",
        "        by_class = []\n",
        "        for count_correct, count_incorrect in zip(count_by_classes_correct, count_by_classes_incorrect):\n",
        "            if count_correct+count_incorrect != 0:\n",
        "                by_class.append(count_correct/(count_correct+count_incorrect))\n",
        "            else:\n",
        "                by_class.append(0)\n",
        "                \n",
        "        prob_correct_by_class.append(by_class)\n",
        "        percentages_correct.append(correct/(correct+incorrect))\n",
        "        \n",
        "    return (percentages_correct, prob_correct_by_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9vapV0ZyWGhA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "percents, prob_by_class = run_nth(ds_derm,0.8,30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aL2WgHrXWGkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "bc7c0438-8f43-4208-8969-f849f897bd6a"
      },
      "cell_type": "code",
      "source": [
        "taxa_acerto_min=np.min(percents)\n",
        "taxa_acerto_max=np.max(percents)\n",
        "taxa_acerto_med=np.mean(percents)\n",
        "\n",
        "print('Taxa de Acerto')\n",
        "print('--------------')\n",
        "print('Minimo: ' + str(taxa_acerto_min))\n",
        "print('Máxima: ' + str(taxa_acerto_max))\n",
        "print('Média: '+str(taxa_acerto_med))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taxa de Acerto\n",
            "--------------\n",
            "Minimo: 0.05555555555555555\n",
            "Máxima: 0.3055555555555556\n",
            "Média: 0.19583333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zSbdou1SWGnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "5093f066-b3ff-41c4-88b4-1937507d1a81"
      },
      "cell_type": "code",
      "source": [
        "print('Taxa de Acerto Médio por classe')\n",
        "print('-------------------------------')\n",
        "\n",
        "ar_value = [ np.mean(m) for m in np.array(prob_by_class).transpose() ]\n",
        "\n",
        "for i, _class in enumerate(ar_value):\n",
        "    print('Classe \\'' +  str(classes[i]) +'\\' : ' + str(_class))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taxa de Acerto Médio por classe\n",
            "-------------------------------\n",
            "Classe '2' : 0.12947723572723574\n",
            "Classe '1' : 0.2973884938590821\n",
            "Classe '3' : 0.16986279372502286\n",
            "Classe '5' : 0.09794370590423221\n",
            "Classe '4' : 0.12676483647071882\n",
            "Classe '6' : 0.033972832722832726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xu0zHxE3WGqG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LhpPYHyPWGte",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D6RJKMXvWG0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KBvo6uMlLLdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2XmsSOZL5l_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}